
let video, faceapi, detections = [];

const OPTIONS = {
  withLandmarks: true,
  withExpressions: true,
  detectionType: 'tiny_face_detector'
};
const MODEL_URL =
  'https://cdn.jsdelivr.net/npm/face-api.js@0.22.2/weights/';

function setup() {
  createCanvas(640, 480);
  video = createCapture(VIDEO).size(width, height).hide();

  // â¶ ë„¤ ë²ˆì§¸ ì¸ìžë¡œ MODEL_URL ì „ë‹¬
  faceapi = ml5.faceApi(video, OPTIONS, modelReady, MODEL_URL);
}

function modelReady() {
  console.log('âœ… ëª¨ë¸(ì–¼êµ´+í‘œì •) ë¡œë“œ ì™„ë£Œ');
  faceapi.detect(gotResults);
}

function gotResults(err, result) {
  if (err) {
    console.error(err);
  } else {
    detections = result;
    console.log('ðŸ” expressions:', detections[0]?.expressions);
  }
  // ë‹¤ìŒ í”„ë ˆìž„ë„ ê³„ì† ê°ì§€
  faceapi.detect(gotResults);
}

function draw() {
  image(video, 0, 0);
  if (!detections.length) return;

  const det = detections[0];
  const box = det.alignedRect._box;

  // íŒŒëž€ ë°•ìŠ¤
  noFill(); stroke(0,200,255); strokeWeight(2);
  rect(box._x, box._y, box._width, box._height);

  // ê°€ìž¥ ë†’ì€ ê°ì • í…ìŠ¤íŠ¸
  const expr = det.expressions;
  if (expr) {
    const [emo, p] = Object.entries(expr)
                           .sort((a,b)=>b[1]-a[1])[0];
    noStroke(); fill(255); textSize(16); textAlign(LEFT,BOTTOM);
    text(`${emo}: ${nf(p*100,1,0)}%`,
         box._x, box._y - 5);
  }
}
